{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nInitial setup:\\n1) create virtualenv project using pycharm\\n\\n2) install the following libraries to virtualenv:\\npip install numpy\\npip install pandas\\npip install requests\\npip install beautifulsoup4\\npip install lxml\\n'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initial setup:\n",
    "1) create virtualenv project using pycharm\n",
    "\n",
    "2) install the following libraries to virtualenv:\n",
    "pip install numpy\n",
    "pip install pandas\n",
    "pip install requests\n",
    "pip install beautifulsoup4\n",
    "pip install lxml\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import requests  # library to send requests to web site(krisha.kz)\n",
    "from bs4 import BeautifulSoup as bs  # library to copy all html-code\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import json\n",
    "from lxml import html\n",
    "import regex\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing: https://kaspi.kz/shop/c/notebooks/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [21], line 47\u001B[0m\n\u001B[1;32m     45\u001B[0m base_url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://kaspi.kz/shop/c/notebooks/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     46\u001B[0m urls \u001B[38;5;241m=\u001B[39m get_all_pages(base_url)\n\u001B[0;32m---> 47\u001B[0m items \u001B[38;5;241m=\u001B[39m \u001B[43mparse_kaspi_pages\u001B[49m\u001B[43m(\u001B[49m\u001B[43murls\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [21], line 40\u001B[0m, in \u001B[0;36mparse_kaspi_pages\u001B[0;34m(urls)\u001B[0m\n\u001B[1;32m     38\u001B[0m data \u001B[38;5;241m=\u001B[39m regex\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m(?:[^\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m]|(?R))*\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mfindall(\u001B[38;5;28mstr\u001B[39m(script))[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     39\u001B[0m data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(data)\n\u001B[0;32m---> 40\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcsvfile.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/KaspiBot/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/KaspiBot/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/KaspiBot/lib/python3.10/site-packages/pandas/io/json/_json.py:733\u001B[0m, in \u001B[0;36mread_json\u001B[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001B[0m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_axes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m orient \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtable\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    731\u001B[0m     convert_axes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 733\u001B[0m json_reader \u001B[38;5;241m=\u001B[39m \u001B[43mJsonReader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    734\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    735\u001B[0m \u001B[43m    \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    739\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_default_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_default_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    742\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprecise_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    744\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    745\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    747\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    748\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnrows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    749\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    750\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding_errors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    751\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    753\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize:\n\u001B[1;32m    754\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m json_reader\n",
      "File \u001B[0;32m~/.conda/envs/KaspiBot/lib/python3.10/site-packages/pandas/io/json/_json.py:818\u001B[0m, in \u001B[0;36mJsonReader.__init__\u001B[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors)\u001B[0m\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlines:\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows can only be passed if lines=True\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 818\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data_from_filepath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    819\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_preprocess_data(data)\n",
      "File \u001B[0;32m~/.conda/envs/KaspiBot/lib/python3.10/site-packages/pandas/io/json/_json.py:858\u001B[0m, in \u001B[0;36mJsonReader._get_data_from_filepath\u001B[0;34m(self, filepath_or_buffer)\u001B[0m\n\u001B[1;32m    851\u001B[0m filepath_or_buffer \u001B[38;5;241m=\u001B[39m stringify_path(filepath_or_buffer)\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_or_buffer, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m    854\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m is_url(filepath_or_buffer)\n\u001B[1;32m    855\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m is_fsspec_url(filepath_or_buffer)\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m file_exists(filepath_or_buffer)\n\u001B[1;32m    857\u001B[0m ):\n\u001B[0;32m--> 858\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    863\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding_errors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    866\u001B[0m     filepath_or_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n\u001B[1;32m    867\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m (\n\u001B[1;32m    868\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(filepath_or_buffer, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m filepath_or_buffer\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39mendswith(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file_exists(filepath_or_buffer)\n\u001B[1;32m    873\u001B[0m ):\n",
      "File \u001B[0;32m~/.conda/envs/KaspiBot/lib/python3.10/site-packages/pandas/io/common.py:713\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    710\u001B[0m     codecs\u001B[38;5;241m.\u001B[39mlookup_error(errors)\n\u001B[1;32m    712\u001B[0m \u001B[38;5;66;03m# open URLs\u001B[39;00m\n\u001B[0;32m--> 713\u001B[0m ioargs \u001B[38;5;241m=\u001B[39m \u001B[43m_get_filepath_or_buffer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    714\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    716\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    717\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    718\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    719\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    721\u001B[0m handle \u001B[38;5;241m=\u001B[39m ioargs\u001B[38;5;241m.\u001B[39mfilepath_or_buffer\n\u001B[1;32m    722\u001B[0m handles: \u001B[38;5;28mlist\u001B[39m[BaseBuffer]\n",
      "File \u001B[0;32m~/.conda/envs/KaspiBot/lib/python3.10/site-packages/pandas/io/common.py:451\u001B[0m, in \u001B[0;36m_get_filepath_or_buffer\u001B[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001B[0m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;28mhasattr\u001B[39m(filepath_or_buffer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(filepath_or_buffer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwrite\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    449\u001B[0m ):\n\u001B[1;32m    450\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid file path or buffer object type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(filepath_or_buffer)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 451\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m IOArgs(\n\u001B[1;32m    454\u001B[0m     filepath_or_buffer\u001B[38;5;241m=\u001B[39mfilepath_or_buffer,\n\u001B[1;32m    455\u001B[0m     encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    458\u001B[0m     mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[1;32m    459\u001B[0m )\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid file path or buffer object type: <class 'dict'>"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'accept': '*/*',\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "items_per_page = 12\n",
    "\n",
    "def get_all_pages(catalog_page_url):\n",
    "    urls = []\n",
    "    urls.append(catalog_page_url)\n",
    "    session = requests.Session()\n",
    "    request = session.get(catalog_page_url, headers=headers)\n",
    "\n",
    "    if request.status_code == 200:\n",
    "        soup = bs(request.content, 'lxml')\n",
    "        try:\n",
    "            pagination = soup.select('li.tree__item._expanded._active')\n",
    "            total_items = int(re.sub('\\D', '', pagination[0].text))\n",
    "            pages = math.ceil(total_items / items_per_page)\n",
    "            for i in range(2, pages):\n",
    "                url = catalog_page_url + '?page={i}'.format(i=i)\n",
    "                if url not in urls:\n",
    "                    urls.append(url)\n",
    "        except Exception as e:\n",
    "            print(\"exception while getting all page urls: \" + e)\n",
    "            pass\n",
    "    return urls\n",
    "\n",
    "def parse_kaspi_pages(urls):\n",
    "    items = []\n",
    "    session = requests.Session()\n",
    "    for url in urls:\n",
    "        time.sleep(1)\n",
    "        print(\"parsing: \" + url)\n",
    "        request = session.get(url, headers=headers)\n",
    "        tree = html.fromstring(request.content)\n",
    "        script = tree.xpath('//script[contains(., \"BACKEND.components.catalogGrid\")]/text()')[0]\n",
    "        data = regex.compile(r\"\\{(?:[^{}]|(?R))*\\}\").findall(str(script))[0]\n",
    "        data = json.loads(data)\n",
    "        df = pd.read_json(data)\n",
    "        df.to_csv('csvfile.csv', encoding='utf-8', index=False)\n",
    "        break\n",
    "    return items\n",
    "\n",
    "base_url = 'https://kaspi.kz/shop/c/notebooks/'\n",
    "urls = get_all_pages(base_url)\n",
    "items = parse_kaspi_pages(urls)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brand': 'Lenovo', 'color': 'серый', 'full_name': 'Lenovo V14-ADA 82C6S03900', 'price': '184800', 'rating': '297'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "items = []\n",
    "with open('Kaspi_data.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    initial = True\n",
    "    for row in spamreader:\n",
    "        if not initial:\n",
    "            title = row[0].split(\" \")\n",
    "            price = re.sub('\\D', '', row[1])\n",
    "            rating = row[2]\n",
    "\n",
    "            items.append({\n",
    "                'brand': title[0],\n",
    "                'color': title[-1],\n",
    "                'full_name': ' '.join(title[:-1]),\n",
    "                'price': price,\n",
    "                'rating': rating,\n",
    "            })\n",
    "        else:\n",
    "            initial = False\n",
    "\n",
    "print(items[0])\n",
    "def files_writer(items):\n",
    "    # with open('HeadHunter.csv', 'a', encoding='utf-8') as file:\n",
    "    with open(r\"Kaspi_data.csv\", \"w\", encoding='utf-8') as file:\n",
    "        a_pen = csv.writer(file)\n",
    "        a_pen.writerow(('brand', 'color', 'full_name', 'price', 'rating'))\n",
    "        for item in items:\n",
    "            a_pen.writerow((item['brand'], item['color'], item['full_name'], item['price'], item['rating']))\n",
    "\n",
    "files_writer(items)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
